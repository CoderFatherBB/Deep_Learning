{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf \n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CAPUCHIN_FILE = os.path.join('data', 'C:/Users/baldo/OneDrive - MSFT/Desktop/Deep Learning/Bird Sound Detection/Sounds/Parsed_Capuchinbird_Clips', 'XC3776-3.wav')\n",
    "NOT_CAPUCHIN_FILE = os.path.join('data', 'C:/Users/baldo/OneDrive - MSFT/Desktop/Deep Learning/Bird Sound Detection/Sounds/Parsed_Not_Capuchinbird_Clips', 'afternoon-birds-song-in-forest-0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels) \n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\baldo\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 458, in f\n        return core_ops.io_audio_resample(\n    File \"C:\\Users\\baldo\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"C:\\Users\\baldo\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"C:\\Users\\baldo\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 69, in _load_library\n        raise NotImplementedError(\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['C:\\\\Users\\\\baldo\\\\anaconda3\\\\envs\\\\gpu3\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n    caused by: ['C:\\\\Users\\\\baldo\\\\anaconda3\\\\envs\\\\gpu3\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m wave \u001b[38;5;241m=\u001b[39m \u001b[43mload_wav_16k_mono\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCAPUCHIN_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m nwave \u001b[38;5;241m=\u001b[39m load_wav_16k_mono(NOT_CAPUCHIN_FILE)\n",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m, in \u001b[0;36mload_wav_16k_mono\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      8\u001b[0m sample_rate \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(sample_rate, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Goes from 44100Hz to 16000hz - amplitude of the audio signal\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m wav \u001b[38;5;241m=\u001b[39m \u001b[43mtfio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wav\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py:462\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(input, rate_in, rate_out, name)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(i):\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_ops\u001b[38;5;241m.\u001b[39mio_audio_resample(\n\u001b[0;32m    459\u001b[0m         i, rate_in\u001b[38;5;241m=\u001b[39mrate_in, rate_out\u001b[38;5;241m=\u001b[39mrate_out, name\u001b[38;5;241m=\u001b[39mname\n\u001b[0;32m    460\u001b[0m     )\n\u001b[1;32m--> 462\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorized_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mg1\u001b[39m():\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msqueeze(value, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\ops\\parallel_for\\control_flow_ops.py:565\u001b[0m, in \u001b[0;36mvectorized_map\u001b[1;34m(fn, elems, fallback_to_while_loop, warn)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    563\u001b[0m   batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(static_first_dims)\n\u001b[1;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpfor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfallback_to_while_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfallback_to_while_loop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\ops\\parallel_for\\control_flow_ops.py:214\u001b[0m, in \u001b[0;36mpfor\u001b[1;34m(loop_fn, iters, fallback_to_while_loop, parallel_iterations, warn)\u001b[0m\n\u001b[0;32m    211\u001b[0m     def_function\u001b[38;5;241m.\u001b[39mrun_functions_eagerly(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    212\u001b[0m   f \u001b[38;5;241m=\u001b[39m def_function\u001b[38;5;241m.\u001b[39mfunction(f)\n\u001b[1;32m--> 214\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m functions_run_eagerly \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m   def_function\u001b[38;5;241m.\u001b[39mrun_functions_eagerly(functions_run_eagerly)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegeyvn29g.py:17\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__f\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(_pfor_impl), (ag__\u001b[38;5;241m.\u001b[39mld(loop_fn), ag__\u001b[38;5;241m.\u001b[39mld(iters)), \u001b[38;5;28mdict\u001b[39m(fallback_to_while_loop\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(fallback_to_while_loop), parallel_iterations\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(parallel_iterations), warn\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(warn)), fscope)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py:458\u001b[0m, in \u001b[0;36mresample.<locals>.f\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(i):\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio_audio_resample\u001b[49m(\n\u001b[0;32m    459\u001b[0m         i, rate_in\u001b[38;5;241m=\u001b[39mrate_in, rate_out\u001b[38;5;241m=\u001b[39mrate_out, name\u001b[38;5;241m=\u001b[39mname\n\u001b[0;32m    460\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:88\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[1;34m(self, attrb)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attrb):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, attrb)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:84\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mod \u001b[38;5;241m=\u001b[39m \u001b[43m_load_library\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_library\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mod\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:69\u001b[0m, in \u001b[0;36m_load_library\u001b[1;34m(filename, lib)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mNotFoundError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     68\u001b[0m         errs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munable to open file: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, from paths: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilenames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mcaused by: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"C:\\Users\\baldo\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 458, in f\n        return core_ops.io_audio_resample(\n    File \"C:\\Users\\baldo\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"C:\\Users\\baldo\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"C:\\Users\\baldo\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 69, in _load_library\n        raise NotImplementedError(\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['C:\\\\Users\\\\baldo\\\\anaconda3\\\\envs\\\\gpu3\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n    caused by: ['C:\\\\Users\\\\baldo\\\\anaconda3\\\\envs\\\\gpu3\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n"
     ]
    }
   ],
   "source": [
    "wave = load_wav_16k_mono(CAPUCHIN_FILE)\n",
    "nwave = load_wav_16k_mono(NOT_CAPUCHIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wave' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\baldo\\OneDrive - MSFT\\Desktop\\Deep Learning\\Bird Sound Detection\\Training\\AudioClassification.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/baldo/OneDrive%20-%20MSFT/Desktop/Deep%20Learning/Bird%20Sound%20Detection/Training/AudioClassification.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(wave)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/baldo/OneDrive%20-%20MSFT/Desktop/Deep%20Learning/Bird%20Sound%20Detection/Training/AudioClassification.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(nwave)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/baldo/OneDrive%20-%20MSFT/Desktop/Deep%20Learning/Bird%20Sound%20Detection/Training/AudioClassification.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wave' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(wave)\n",
    "plt.plot(nwave)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "POS = os.path.join('data', '../Sounds/Parsed_Capuchinbird_Clips')\n",
    "NEG = os.path.join('data', '../Sounds/Parsed_Not_Capuchinbird_Clips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: data\\\\../Sounds/Parsed_Capuchinbird_Clips/*.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\baldo\\OneDrive - MSFT\\Desktop\\Deep Learning\\Bird Sound Detection\\Training\\AudioClassification.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/baldo/OneDrive%20-%20MSFT/Desktop/Deep%20Learning/Bird%20Sound%20Detection/Training/AudioClassification.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pos \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mlist_files(POS\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/*.wav\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/baldo/OneDrive%20-%20MSFT/Desktop/Deep%20Learning/Bird%20Sound%20Detection/Training/AudioClassification.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m neg \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mlist_files(NEG\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/*.wav\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\baldo\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1384\u001b[0m, in \u001b[0;36mDatasetV2.list_files\u001b[1;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[0;32m   1377\u001b[0m condition \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39mgreater(array_ops\u001b[39m.\u001b[39mshape(matching_files)[\u001b[39m0\u001b[39m], \u001b[39m0\u001b[39m,\n\u001b[0;32m   1378\u001b[0m                              name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmatch_not_empty\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1380\u001b[0m message \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39madd(\n\u001b[0;32m   1381\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mNo files matched pattern: \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1382\u001b[0m     string_ops\u001b[39m.\u001b[39mreduce_join(file_pattern, separator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m), name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1384\u001b[0m assert_not_empty \u001b[39m=\u001b[39m control_flow_ops\u001b[39m.\u001b[39;49mAssert(\n\u001b[0;32m   1385\u001b[0m     condition, [message], summarize\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39massert_not_empty\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   1386\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcontrol_dependencies([assert_not_empty]):\n\u001b[0;32m   1387\u001b[0m   matching_files \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39midentity(matching_files)\n",
      "File \u001b[1;32mc:\\Users\\baldo\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\baldo\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:156\u001b[0m, in \u001b[0;36mAssert\u001b[1;34m(condition, data, summarize, name)\u001b[0m\n\u001b[0;32m    154\u001b[0m     xs \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_n_to_tensor(data)\n\u001b[0;32m    155\u001b[0m     data_str \u001b[39m=\u001b[39m [_summarize_eager(x, summarize) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m xs]\n\u001b[1;32m--> 156\u001b[0m     \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError(\n\u001b[0;32m    157\u001b[0m         node_def\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m         op\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    159\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to be true. Summarized data: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m    160\u001b[0m         (condition, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(data_str)))\n\u001b[0;32m    161\u001b[0m   \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mAssert\u001b[39m\u001b[39m\"\u001b[39m, [condition, data]) \u001b[39mas\u001b[39;00m name:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: data\\\\../Sounds/Parsed_Capuchinbird_Clips/*.wav'"
     ]
    }
   ],
   "source": [
    "pos = tf.data.Dataset.list_files(POS+'/*.wav')\n",
    "neg = tf.data.Dataset.list_files(NEG+'/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\baldo\\OneDrive - MSFT\\Desktop\\Deep Learning\\Bird Sound Detection\\Training\\AudioClassification.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/baldo/OneDrive%20-%20MSFT/Desktop/Deep%20Learning/Bird%20Sound%20Detection/Training/AudioClassification.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m positives \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mzip((pos, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices(tf\u001b[39m.\u001b[39mones(\u001b[39mlen\u001b[39m(pos)))))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/baldo/OneDrive%20-%20MSFT/Desktop/Deep%20Learning/Bird%20Sound%20Detection/Training/AudioClassification.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m negatives \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mzip((neg, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices(tf\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(neg)))))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/baldo/OneDrive%20-%20MSFT/Desktop/Deep%20Learning/Bird%20Sound%20Detection/Training/AudioClassification.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data \u001b[39m=\u001b[39m positives\u001b[39m.\u001b[39mconcatenate(negatives)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pos' is not defined"
     ]
    }
   ],
   "source": [
    "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
    "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for file in os.listdir(os.path.join('data', 'Parsed_Capuchinbird_Clips')):\n",
    "    tensor_wave = load_wav_16k_mono(os.path.join('data', 'Parsed_Capuchinbird_Clips', file))\n",
    "    lengths.append(len(tensor_wave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.math.reduce_mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.math.reduce_min(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.math.reduce_max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(file_path, label): \n",
    "    wav = load_wav_16k_mono(file_path)\n",
    "    wav = wav[:48000]\n",
    "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, wav],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spectrogram, label = preprocess(filepath, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(tf.transpose(spectrogram)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.map(preprocess)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "data = data.batch(16)\n",
    "data = data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = data.take(36)\n",
    "test = data.skip(36).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples, labels = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257,1)))\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=4, validation_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'], 'r')\n",
    "plt.plot(hist.history['val_loss'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Precision')\n",
    "plt.plot(hist.history['precision'], 'r')\n",
    "plt.plot(hist.history['val_precision'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Recall')\n",
    "plt.plot(hist.history['recall'], 'r')\n",
    "plt.plot(hist.history['val_recall'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test, y_test = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_mp3_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    res = tfio.audio.AudioIOTensor(filename)\n",
    "    # Convert to tensor and combine channels \n",
    "    tensor = res.to_tensor()\n",
    "    tensor = tf.math.reduce_sum(tensor, axis=1) / 2 \n",
    "    # Extract sample rate and cast\n",
    "    sample_rate = res.rate\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Resample to 16 kHz\n",
    "    wav = tfio.audio.resample(tensor, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mp3 = os.path.join('data', 'Forest Recordings', 'recording_00.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wav = load_mp3_16k_mono(mp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "samples, index = audio_slices.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_mp3(sample, index):\n",
    "    sample = sample[0]\n",
    "    zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, sample],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=16000, sequence_stride=16000, batch_size=1)\n",
    "audio_slices = audio_slices.map(preprocess_mp3)\n",
    "audio_slices = audio_slices.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(audio_slices)\n",
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "yhat = [key for key, group in groupby(yhat)]\n",
    "calls = tf.math.reduce_sum(yhat).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for file in os.listdir(os.path.join('data', 'Forest Recordings')):\n",
    "    FILEPATH = os.path.join('data','Forest Recordings', file)\n",
    "    \n",
    "    wav = load_mp3_16k_mono(FILEPATH)\n",
    "    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
    "    audio_slices = audio_slices.map(preprocess_mp3)\n",
    "    audio_slices = audio_slices.batch(64)\n",
    "    \n",
    "    yhat = model.predict(audio_slices)\n",
    "    \n",
    "    results[file] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_preds = {}\n",
    "for file, logits in results.items():\n",
    "    class_preds[file] = [1 if prediction > 0.99 else 0 for prediction in logits]\n",
    "class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "postprocessed = {}\n",
    "for file, scores in class_preds.items():\n",
    "    postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()\n",
    "postprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open('results.csv', 'w', newline='') as f:\n",
    "#     writer = csv.writer(f, delimiter=',')\n",
    "#     writer.writerow(['recording', 'capuchin_calls'])\n",
    "#     for key, value in postprocessed.items():\n",
    "#         writer.writerow([key, value])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu3",
   "language": "python",
   "name": "gpu3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
